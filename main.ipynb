{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tải thành công: K_tep.jpg\n",
      "Tải thành công: K_ro.jpg\n",
      "Tải thành công: K_co.jpg\n",
      "Tải thành công: K_bich.jpg\n",
      "Tải thành công: Q_tep.jpg\n",
      "Tải thành công: Q_ro.jpg\n",
      "Tải thành công: Q_co.jpg\n",
      "Tải thành công: Q_bich.jpg\n",
      "Tải thành công: J_tep.jpg\n",
      "Tải thành công: J_ro.jpg\n",
      "Tải thành công: J_co.jpg\n",
      "Tải thành công: J_bich.jpg\n",
      "Tải thành công: 10_tep.jpg\n",
      "Tải thành công: 10_ro.jpg\n",
      "Tải thành công: 10_co.jpg\n",
      "Tải thành công: 10_bich.jpg\n",
      "Tải thành công: 9_tep.jpg\n",
      "Tải thành công: 9_ro.jpg\n",
      "Tải thành công: 9_co.jpg\n",
      "Tải thành công: 9_bich.jpg\n",
      "Tải thành công: 8_tep.jpg\n",
      "Tải thành công: 8_ro.jpg\n",
      "Tải thành công: 8_co.jpg\n",
      "Tải thành công: 8_bich.jpg\n",
      "Tải thành công: 7_tep.jpg\n",
      "Tải thành công: 7_ro.jpg\n",
      "Tải thành công: 7_co.jpg\n",
      "Tải thành công: 7_bich.jpg\n",
      "Tải thành công: 6_tep.jpg\n",
      "Tải thành công: 6_ro.jpg\n",
      "Tải thành công: 6_co.jpg\n",
      "Tải thành công: 6_bich.jpg\n",
      "Tải thành công: 5_tep.jpg\n",
      "Tải thành công: 5_ro.jpg\n",
      "Tải thành công: 5_co.jpg\n",
      "Tải thành công: 5_bich.jpg\n",
      "Tải thành công: 4_tep.jpg\n",
      "Tải thành công: 4_ro.jpg\n",
      "Tải thành công: 4_co.jpg\n",
      "Tải thành công: 4_bich.jpg\n",
      "Tải thành công: 3_tep.jpg\n",
      "Tải thành công: 3_ro.jpg\n",
      "Tải thành công: 3_co.jpg\n",
      "Tải thành công: 3_bich.jpg\n",
      "Tải thành công: 2_tep.jpg\n",
      "Tải thành công: 2_ro.jpg\n",
      "Tải thành công: 2_co.jpg\n",
      "Tải thành công: 2_bich.jpg\n",
      "Tải thành công: A_tep.jpg\n",
      "Tải thành công: A_ro.jpg\n",
      "Tải thành công: A_co.jpg\n",
      "Tải thành công: A_bich.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Tạo thư mục 'poker' nếu chưa tồn tại\n",
    "if not os.path.exists('poker'):\n",
    "    os.makedirs('poker')\n",
    "\n",
    "# Các chất bài (tép, rô, cơ, bích)\n",
    "suits = ['tep', 'ro', 'co', 'bich']\n",
    "\n",
    "# Giá trị của lá bài từ K (13) xuống A (1)\n",
    "values = {13: 'K', 12: 'Q', 11: 'J', 10: '10', 9: '9', 8: '8', 7: '7', 6: '6', 5: '5', 4: '4', 3: '3', 2: '2', 1: 'A'}\n",
    "\n",
    "# Đọc file chứa đường dẫn các lá bài\n",
    "with open('./link_bai.txt', 'r') as f:\n",
    "    links = f.readlines()\n",
    "\n",
    "# Kiểm tra xem số đường dẫn có đủ 52 lá bài hay không\n",
    "if len(links) != 52:\n",
    "    raise ValueError(\"Số lượng đường dẫn không đủ 52 lá bài!\")\n",
    "\n",
    "# Tải từng lá bài về theo thứ tự giá trị và chất\n",
    "index = 0\n",
    "for value in range(13, 0, -1):  # Từ K (13) đến A (1)\n",
    "    for suit in suits:\n",
    "        # Đường dẫn ảnh\n",
    "        link = links[index].strip()\n",
    "        # Tên file ảnh theo giá trị và chất (ví dụ: K_tep.jpg)\n",
    "        filename = f'{values[value]}_{suit}.jpg'\n",
    "        # Đường dẫn lưu vào thư mục 'poker'\n",
    "        filepath = os.path.join('poker', filename)\n",
    "\n",
    "        # Tải ảnh về\n",
    "        response = requests.get(link)\n",
    "        if response.status_code == 200:\n",
    "            # Ghi file ảnh\n",
    "            with open(filepath, 'wb') as img_file:\n",
    "                img_file.write(response.content)\n",
    "            print(f\"Tải thành công: {filename}\")\n",
    "        else:\n",
    "            print(f\"Không thể tải ảnh từ {link}\")\n",
    "\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tăng cường dữ liệu hoàn tất!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Đường dẫn đến thư mục chứa hình ảnh bài\n",
    "data_dir = './poker'\n",
    "\n",
    "# Tạo thư mục lưu trữ ảnh đã tăng cường\n",
    "augmented_dir = './poker_augmented'\n",
    "if not os.path.exists(augmented_dir):\n",
    "    os.makedirs(augmented_dir)\n",
    "\n",
    "# Các thông số tăng cường dữ liệu\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,      # Xoay ngẫu nhiên trong khoảng 30 độ\n",
    "    width_shift_range=0.1,  # Dịch chuyển theo chiều ngang\n",
    "    height_shift_range=0.1, # Dịch chuyển theo chiều dọc\n",
    "    shear_range=0.2,        # Biến đổi hình ảnh theo góc xiên\n",
    "    zoom_range=0.2,         # Phóng to hoặc thu nhỏ ngẫu nhiên\n",
    "    horizontal_flip=True,   # Lật ngang\n",
    "    brightness_range=(0.5, 1.5)  # Thay đổi độ sáng\n",
    ")\n",
    "\n",
    "# Hàm để tạo tên thư mục theo lá bài (VD: 2_tep, K_co, A_bich)\n",
    "def get_card_folder_name(filename):\n",
    "    # Giả sử tên file là \"K_co.jpg\" hoặc \"2_tep.jpg\"\n",
    "    card_name = filename.split('.')[0]  # Bỏ phần đuôi \".jpg\"\n",
    "    return card_name\n",
    "\n",
    "# Duyệt qua tất cả các hình ảnh trong thư mục gốc\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(data_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((150, 150))  # Resize về kích thước nhỏ hơn cho nhanh\n",
    "\n",
    "        # Chuyển đổi hình ảnh sang chế độ RGB nếu cần thiết\n",
    "        if img.mode == 'RGBA':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        # Tạo thư mục con theo lá bài (VD: 2_tep, A_co)\n",
    "        card_folder_name = get_card_folder_name(filename)\n",
    "        card_folder_path = os.path.join(augmented_dir, card_folder_name)\n",
    "        \n",
    "        # Tạo thư mục nếu chưa tồn tại\n",
    "        if not os.path.exists(card_folder_path):\n",
    "            os.makedirs(card_folder_path)\n",
    "\n",
    "        # Chuyển hình ảnh sang numpy array\n",
    "        x = np.array(img)\n",
    "        x = x.reshape((1,) + x.shape)  # Thêm batch dimension\n",
    "\n",
    "        # Tạo ra 10 phiên bản ảnh từ một ảnh gốc và lưu vào thư mục con tương ứng\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=card_folder_path, save_prefix=filename.split('.')[0], save_format='jpg'):\n",
    "            i += 1\n",
    "            if i >= 10:  # Tạo 10 ảnh tăng cường cho mỗi quân bài\n",
    "                break\n",
    "\n",
    "print(\"Tăng cường dữ liệu hoàn tất!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 52 classes.\n",
      "Found 104 images belonging to 52 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoangks5\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 385ms/step - accuracy: 0.0112 - loss: 4.1453 - val_accuracy: 0.0481 - val_loss: 3.9418\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.0634 - loss: 3.9129 - val_accuracy: 0.0385 - val_loss: 3.7928\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.0762 - loss: 3.5468 - val_accuracy: 0.0673 - val_loss: 3.5008\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.3661 - loss: 2.5321 - val_accuracy: 0.1058 - val_loss: 3.8714\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 253ms/step - accuracy: 0.5885 - loss: 1.4870 - val_accuracy: 0.0962 - val_loss: 4.4677\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 256ms/step - accuracy: 0.7983 - loss: 0.7152 - val_accuracy: 0.0962 - val_loss: 5.5604\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.9168 - loss: 0.3238 - val_accuracy: 0.1346 - val_loss: 6.6172\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - accuracy: 0.9486 - loss: 0.1758 - val_accuracy: 0.1250 - val_loss: 7.0161\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.9774 - loss: 0.1054 - val_accuracy: 0.1346 - val_loss: 6.9660\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 255ms/step - accuracy: 0.9945 - loss: 0.0272 - val_accuracy: 0.1635 - val_loss: 7.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn mới đến tập dữ liệu đã được tăng cường\n",
    "augmented_data_dir = './poker_augmented'\n",
    "\n",
    "# Tạo lại trình tạo dữ liệu cho việc huấn luyện và xác thực\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    augmented_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    augmented_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Xây dựng mô hình như trước đó\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('card_recognition_augmented_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Mô hình dự đoán: J_bich\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Đọc ảnh mới và dự đoán\n",
    "img_path = './poker/Q_bich.jpg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))  # Kích thước ảnh mà mô hình được huấn luyện\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Thêm chiều batch dimension\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Lấy tên class từ các thư mục đã dùng để train\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(f\"Mô hình dự đoán: {class_names[predicted_class[0]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
